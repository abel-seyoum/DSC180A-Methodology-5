Abel Seyoum (aseyoum@ucsd.edu)
Stochastic Optimization in Over-Parameterized Models: Neural Networks and Kernel Machines (B13) - Prof. Mikhail Belkin & Prof. Yi-an Ma

Questions
1. **What is the most interesting topic covered in your domain this quarter?**
   The most interesting topic we have covered in my domain this quarter has been the topic of feature learning, especially in the context of wide neural networks. We currently know that neural networks are able to understand the underlying patterns in data very well, however we really do not understand how they are able to do so.

2. **Describe a potential investigation you would like to pursue for your Quarter 2 Project.**
    A potential investigation I would like to pursue for the quarter 2 project would be to combine a topic presented in our summer readings, which was on the effects of early stopping during the training of neural networks. Specifically, I would like to combine what I have learned about feature learning thus far, and see how the features learn while training is cut short. Often times, models are not trained till convergence (ex. GPT-4 was not fully trained), and thus it would be interesting to see the effects of how the features learned in both fully trained and early stopped training scenarios.

3. **What is a potential change youâ€™d make to the approach taken in your current Quarter 1 Project?**
   A potential change I would make to the current approach taken in my current Quarter 1 Project would have been to set up 1:1 meetings with our advisors earlier in order to get a clearer understanding of our end of quarter deliverable.

   **What other techniques would you be interested in using in your project?**
   Another technique I would be interested in using in my project would be some more NLP type of tasks, specifically understanding how features in language models learn (right now we are doing a lot of image based learning tasks).
